{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, re, matplotlib.pyplot as plt, seaborn as sns, nltk, string\n",
    "import warnings, itertools\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "from utils import *\n",
    "\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, Dropout, Flatten, Bidirectional, TimeDistributed\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to plot of the history\n",
    "def plot_hist(history):\n",
    "    acc = history.history['acc']\n",
    "    val_acc = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    x = range(1, len(acc) + 1)\n",
    "    \n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(x, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(x, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and Validation accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(x, loss, 'b', label='Training loss')\n",
    "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Train and Validation Loss')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to parse tweets\n",
    "def clean_content(tweets):\n",
    "        \n",
    "    ''' script to parse out punctuation, numbers, special chars, short words repeated letters, white spaces, @handles and urls'''\n",
    "    \n",
    "    # create new Series, remove @user reference\n",
    "    combine['clean_content'] = combine['content'].apply(lambda x: re.sub(r'@\\w+', ' ',x))\n",
    "    # remove rt| cc\n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: re.sub('rt|cc', ' ',x))\n",
    "    # remove url related info, replace with URL\n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: re.sub(r'((www\\.[\\S]+)|(https?://[\\S]+))', 'URL',x))\n",
    "    # remove punctuation \n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: re.sub('[^a-zA-Z]', ' ',x))\n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: re.sub('[#]', ' ',x))\n",
    "    # remove repeating letters, i.e funnnny => funny\n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: re.sub(r'(.)\\1+', r'\\1\\1', x))\n",
    "    # remove white spaces\n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: re.sub('  ', ' ', x))\n",
    "    # remove short words \n",
    "    combine['clean_content'] = combine['clean_content'].apply(lambda x: ' '.join([t for t in x.split() if len(t)>3]))\n",
    "    \n",
    "    tokenized_twt = combine['clean_content'].apply(lambda x: x.split())\n",
    "    stemmer = PorterStemmer()\n",
    "    tokenized_twt = tokenized_twt.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming function\n",
    "    # put tokens back together\n",
    "    for i in range(len(tokenized_twt)):\n",
    "        tokenized_twt[i] = ' '.join(tokenized_twt[i])\n",
    "\n",
    "    combine['clean_content'] = tokenized_twt\n",
    "    \n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return accuracy of the evaluation dataset\n",
    "def lstm_accuracy(y_orig,y_hat):\n",
    "    count =0\n",
    "    for i in range(len(y_orig)):\n",
    "        if y_orig[i] == y_hat[i]:\n",
    "            count += 1\n",
    "        count\n",
    "    return count/prediction.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasets\n",
    "train = pd.read_csv('../data/train.csv', encoding='utf-8')\n",
    "evaluate = pd.read_csv('../data/evaluate.csv',encoding='utf-8')\n",
    "\n",
    "# merge documents and preprocess together, separate back to train/evaluate sets after\n",
    "combine = train.append(evaluate, ignore_index=True).apply(lambda x: x.astype(str).str.lower())\n",
    "combine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine = clean_content(combine)\n",
    "combine.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sentiment dictionary and label feature\n",
    "sentiment_dic = {'positive':1, 'neutral': 0, 'negative':-1 }\n",
    "combine['sentiment_label'] = combine['sentiment'].map(sentiment_dic)\n",
    "combine.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data back to train and evaluate sets\n",
    "train = combine.iloc[:160000,-2:]\n",
    "evaluate = combine.iloc[160000:,-2:]\n",
    "\n",
    "# print(train.shape, evaluate.shape)\n",
    "# print(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract values from the dataframe objects\n",
    "y = train['sentiment_label'].values\n",
    "sentences = train['clean_content'].values\n",
    "\n",
    "y_rnn = keras.utils.to_categorical(y, num_classes=3)\n",
    "\n",
    "# find the max number of words in sentences\n",
    "combine['token_length'] = [len(x.split(' ')) for x in combine.clean_content]\n",
    "maxlen = max(combine.token_length)\n",
    "print(maxlen)\n",
    "\n",
    "# split of strings of text into individual tokens\n",
    "tokenizer = Tokenizer(num_words=12000, oov_token = True)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# set vectors to process in the network\n",
    "X_pad = pad_sequences(sequences,padding='post', maxlen=40)\n",
    "\n",
    "#split into train and validation set for rnn\n",
    "X_train_seq, X_val_seq, y_trainRNN, y_valRNN = train_test_split(X_pad, y_rnn, random_state=44, test_size=0.2)\n",
    "X_train_seq, X_val_seq, y_train, y_val = train_test_split(X_pad, y, random_state=44, test_size=0.2)\n",
    "\n",
    "# Oversampling, increasing # of sample points with the norm\n",
    "smote = SMOTE(ratio='auto', n_jobs=-1)\n",
    "X_smote,y_smote = smote.fit_sample(X_train_seq, y_train)\n",
    "\n",
    "y_trainRNN = keras.utils.to_categorical(y_smote, num_classes=3)\n",
    "y_valRNN = keras.utils.to_categorical(y_val, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm correct dimensions\n",
    "print(X_train_seq.shape, X_val_seq.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define FeedForward baseline model\n",
    "def baseline_model():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=40, activation='relu'))\n",
    "    model.add(Dense(128))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=5, batch_size=128, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = baseline_model()\n",
    "\n",
    "FF_preds = base_model.predict(X_val_seq)\n",
    "# predFF[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = KFold(n_splits=5, shuffle=False, random_state=seed)\n",
    "results = cross_val_score(estimator, X_train_seq, y_train, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare LogisticRegression and Naive Bayes model performance\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Establish additional baseline models, fit the models on train set, evaluate on validation set\n",
    "# build logistic regression model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train_seq, y_train)\n",
    "lr_score = classifier.score(X_val_seq, y_val)\n",
    "lr_yhat_val = classifier.predict(X_val_seq)\n",
    "print('Accuracy for tweet sentiment with Logistic Regression: {:.3f}%'.format(lr_score*100))\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure(1, figsize=(5,5))\n",
    "cm = confusion_matrix(y_val, lr_yhat_val)\n",
    "sns.heatmap(cm.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "           xticklabels=['Positive', 'Neutral', 'Negative'], yticklabels=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title('Logisitic Regression Confusion Matrix - Validation Set')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')\n",
    "\n",
    "# Build Naive Bayes Model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_seq, y_train)\n",
    "bayes_score = model.score(X_val_seq, y_val)\n",
    "bayes_yhat_val = model.predict(X_val_seq)\n",
    "print('Accuracy for tweet sentiment with Naive Bayes: {:.3f}%'.format(bayes_score*100))\n",
    "\n",
    "# plot confusion matrix\n",
    "plt.figure(2, figsize=(5,5))\n",
    "cm = confusion_matrix(y_val, bayes_yhat_val)\n",
    "sns.heatmap(cm.T, square=True, annot=True, fmt='d', cbar=False,\n",
    "           xticklabels=['Positive', 'Neutral', 'Negative'], yticklabels=['Positive', 'Neutral', 'Negative'])\n",
    "plt.title('Navies Bayes Confusion Matrix - Validation')\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define LSTM model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "vocab_size = 12000\n",
    "embedding_size = 50\n",
    "maxlen = 40\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, embedding_size, input_length=40))\n",
    "model.add(Bidirectional(LSTM(128, dropout=0.5, activation='relu',return_sequences=True)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(TimeDistributed(Dense(50, activation='relu')))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit network\n",
    "batch_size = 128\n",
    "num_epochs = 10\n",
    "\n",
    "save_dir = '../NLP'\n",
    "\n",
    "callbacks=[EarlyStopping(patience=5, monitor='loss', min_delta=0.0001),\n",
    "           ModelCheckpoint(filepath=save_dir + \"/\" + 'twitter_analysis_model.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n",
    "                           monitor='loss', verbose=0, mode='auto', period=5)]\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_smote, y_trainRNN, epochs=num_epochs, batch_size=batch_size, validation_data=(X_val_seq, y_valRNN),\n",
    "                    callbacks=callbacks, verbose=1, shuffle=False)\n",
    "\n",
    "# save the model\n",
    "model.save(save_dir + \"/\" + 'my_model_generate_sentences.h5')\n",
    "\n",
    "# plot history of training / validation metrics\n",
    "plot_hist(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process evaluation data for network\n",
    "evaluate_data = evaluate.values\n",
    "X_eval = evaluate_data[:,0]\n",
    "y_eval = evaluate_data[:,1]\n",
    "y_evalRNN = keras.utils.to_categorical(y_eval, num_classes=3)\n",
    "# print('y_eval shape', y_eval.shape)\n",
    "# print('y_evalRNN shape', y_evalRNN.shape)\n",
    "\n",
    "# apply the same tokenizer from train set on the evaluate set \n",
    "sequences = tokenizer.texts_to_sequences(X_eval)\n",
    "# set vectors to process in the network\n",
    "X_eval_seq = pad_sequences(sequences, maxlen=40)\n",
    "\n",
    "# test on evaluation set\n",
    "\n",
    "prediction = model.predict_classes(X_eval_seq, verbose=1)\n",
    "\n",
    "y_orig = [np.argmax(y, axis=None, out=None) for y in y_evalRNN]\n",
    "y_hat = [np.argmax(y, axis=None, out=None) for y in prediction]\n",
    "\n",
    "\n",
    "lstm_accuracy(y_orig, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot classification report and confusion matrix \n",
    "from sklearn import metrics\n",
    "\n",
    "# confusion matrix\n",
    "\n",
    "mat = confusion_matrix(y_orig, prediction)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False, xticklabels=['negative','neutral','positive'],\n",
    "           yticklabels=['negative','neutral','positive'])\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
